{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers==4.47.0\n",
    "!pip install datasets==3.2.0\n",
    "!pip install trl==0.14.0\n",
    "!pip install peft==0.14.0\n",
    "!pip install numpy==1.26.4\n",
    "!pip install huggingface_hub==0.27.0\n",
    "!pip install tqdm==4.67.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T14:18:19.810251Z",
     "iopub.status.busy": "2025-02-03T14:18:19.809924Z",
     "iopub.status.idle": "2025-02-03T14:18:20.125896Z",
     "shell.execute_reply": "2025-02-03T14:18:20.125136Z",
     "shell.execute_reply.started": "2025-02-03T14:18:19.810229Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "import random\n",
    "import numpy\n",
    "\n",
    "# empty cache\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# set the seed\n",
    "seed = 28\n",
    "torch.manual_seed(seed)\n",
    "numpy.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# device check\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T14:18:20.139598Z",
     "iopub.status.busy": "2025-02-03T14:18:20.139401Z",
     "iopub.status.idle": "2025-02-03T14:18:28.450274Z",
     "shell.execute_reply": "2025-02-03T14:18:28.449348Z",
     "shell.execute_reply.started": "2025-02-03T14:18:20.139580Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2db1b2f390804116995122d58cc536ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/861 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aab3065c0a3a406898e3f0fa055dcca8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/269M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3ef5836f2004fe2940f8877ac3b7098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,843,200 || all params: 136,358,208 || trainable%: 1.3517\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=64,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model_name = \"HuggingFaceTB/SmolLM2-135M-Instruct\"\n",
    "base_model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "policy_model = get_peft_model(base_model, lora_config).to(device)\n",
    "policy_model.train()\n",
    "policy_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T14:18:28.452099Z",
     "iopub.status.busy": "2025-02-03T14:18:28.451757Z",
     "iopub.status.idle": "2025-02-03T14:18:30.152404Z",
     "shell.execute_reply": "2025-02-03T14:18:30.151527Z",
     "shell.execute_reply.started": "2025-02-03T14:18:28.452067Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "157a46cb72cf4d6391710fe8713bedab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/3.76k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8d11138757b447ca827a800572031fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/801k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36693142c37643d5b2cdb84c3620fca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3600b45434624010956ac77484f5f3d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bb10ab313fc4fbda984b248607c83ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/655 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.padding_side = \"left\"\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T14:18:30.153592Z",
     "iopub.status.busy": "2025-02-03T14:18:30.153365Z",
     "iopub.status.idle": "2025-02-03T14:18:30.183838Z",
     "shell.execute_reply": "2025-02-03T14:18:30.182985Z",
     "shell.execute_reply.started": "2025-02-03T14:18:30.153573Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable blocks: 120\n",
      "Trainable blocks:\n",
      "- base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight\n",
      "- base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight\n",
      "- base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight\n",
      "\n",
      "Total trainable parameters: 1,843,200\n"
     ]
    }
   ],
   "source": [
    "trainable_params = [n for n, p in policy_model.named_parameters() if p.requires_grad]\n",
    "print(f\"Number of trainable blocks: {len(trainable_params)}\")\n",
    "print(\"Trainable blocks:\")\n",
    "for param_name in trainable_params:\n",
    "    print(f\"- {param_name}\")\n",
    "\n",
    "total_trainable = sum(p.numel() for p in policy_model.parameters() if p.requires_grad)\n",
    "print(f\"\\nTotal trainable parameters: {total_trainable:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T14:18:30.185157Z",
     "iopub.status.busy": "2025-02-03T14:18:30.184793Z",
     "iopub.status.idle": "2025-02-03T14:18:37.769987Z",
     "shell.execute_reply": "2025-02-03T14:18:37.769282Z",
     "shell.execute_reply.started": "2025-02-03T14:18:30.185096Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5fa4682b75d477ab6e96451d9ab6f01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.48k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eeff68500644bffa56e2ba42604897a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/269M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LlamaForSequenceClassification(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(49152, 576, padding_idx=2)\n",
       "    (layers): ModuleList(\n",
       "      (0-29): 30 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=576, out_features=576, bias=False)\n",
       "          (k_proj): Linear(in_features=576, out_features=192, bias=False)\n",
       "          (v_proj): Linear(in_features=576, out_features=192, bias=False)\n",
       "          (o_proj): Linear(in_features=576, out_features=576, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=576, out_features=1536, bias=False)\n",
       "          (up_proj): Linear(in_features=576, out_features=1536, bias=False)\n",
       "          (down_proj): Linear(in_features=1536, out_features=576, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((576,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((576,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((576,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (score): Linear(in_features=576, out_features=10, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "rm_name = \"MilyaShams/SmolLM2-135M-Instruct-Reward-probabilistic\"\n",
    "reward_model = AutoModelForSequenceClassification.from_pretrained(rm_name, num_labels=10).to(device)\n",
    "reward_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T14:18:37.771026Z",
     "iopub.status.busy": "2025-02-03T14:18:37.770732Z",
     "iopub.status.idle": "2025-02-03T14:18:42.852124Z",
     "shell.execute_reply": "2025-02-03T14:18:42.851450Z",
     "shell.execute_reply.started": "2025-02-03T14:18:37.770993Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb4422dd832d4d56b89795c14651206f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/1.19k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0df89b31c2f48538a01fce7624e8cd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)rage_rating_split-00000-of-00001.parquet:   0%|          | 0.00/22.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84f3f9d806ba4309a64d51a6817ee938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)o_verbosity_split-00000-of-00001.parquet:   0%|          | 0.00/21.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "391b842ece7a474aaf67b33da098a5cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)_complexity_split-00000-of-00001.parquet:   0%|          | 0.00/20.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7cb17c94ede47b1a192377cc93ad246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)dness_score_split-00000-of-00001.parquet:   0%|          | 0.00/21.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5112110afb8a433098db34475c3308ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating average_rating_split split:   0%|          | 0/8678 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43cf198b6c504959be63316d0ac18866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating average_rating_no_verbosity_split split:   0%|          | 0/8315 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c64db27d0af94ae4bc931db3c1883de1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating average_rating_no_verbosity_no_complexity_split split:   0%|          | 0/8025 [00:00<?, ? examples…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20d5e970722845bfa0ae7dabe05967b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating goodness_score_split split:   0%|          | 0/8124 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"esfrankel17/HelpSteer2_binarized\", split='average_rating_split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T14:18:42.854447Z",
     "iopub.status.busy": "2025-02-03T14:18:42.854216Z",
     "iopub.status.idle": "2025-02-03T14:18:42.859001Z",
     "shell.execute_reply": "2025-02-03T14:18:42.858359Z",
     "shell.execute_reply.started": "2025-02-03T14:18:42.854426Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'chosen', 'chosen_rating', 'rejected', 'rejected_rating'],\n",
       "    num_rows: 8678\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T14:18:42.860582Z",
     "iopub.status.busy": "2025-02-03T14:18:42.860373Z",
     "iopub.status.idle": "2025-02-03T14:18:43.541033Z",
     "shell.execute_reply": "2025-02-03T14:18:43.540289Z",
     "shell.execute_reply.started": "2025-02-03T14:18:42.860565Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3361 5310 3996\n"
     ]
    }
   ],
   "source": [
    "prompts = [len(item[\"prompt\"]) for item in dataset]\n",
    "\n",
    "n_long = 0\n",
    "n_ok = 0\n",
    "n_good = 0\n",
    "\n",
    "for i in prompts:\n",
    "    if i > 512:\n",
    "        n_long += 1\n",
    "    if i < 512:\n",
    "        n_ok += 1\n",
    "    if i < 200:\n",
    "        n_good += 1\n",
    "\n",
    "print(n_long, n_ok, n_good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T14:18:43.542014Z",
     "iopub.status.busy": "2025-02-03T14:18:43.541777Z",
     "iopub.status.idle": "2025-02-03T14:18:43.857366Z",
     "shell.execute_reply": "2025-02-03T14:18:43.856489Z",
     "shell.execute_reply.started": "2025-02-03T14:18:43.541991Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43eab98480bf4361a27828a7c3c22ba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/8678 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Фильтрация датсета, чтобы извлечь только короткие промпты (<200 символов)\n",
    "filtered_dataset = dataset.filter(lambda example: len(example['prompt']) < 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T14:18:43.858506Z",
     "iopub.status.busy": "2025-02-03T14:18:43.858248Z",
     "iopub.status.idle": "2025-02-03T14:18:43.863092Z",
     "shell.execute_reply": "2025-02-03T14:18:43.862372Z",
     "shell.execute_reply.started": "2025-02-03T14:18:43.858484Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'chosen', 'chosen_rating', 'rejected', 'rejected_rating'],\n",
       "    num_rows: 3996\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T14:18:43.864083Z",
     "iopub.status.busy": "2025-02-03T14:18:43.863854Z",
     "iopub.status.idle": "2025-02-03T14:18:43.884776Z",
     "shell.execute_reply": "2025-02-03T14:18:43.883974Z",
     "shell.execute_reply.started": "2025-02-03T14:18:43.864063Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "filtered_dataset = filtered_dataset.train_test_split(test_size=0.2, shuffle=True, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T14:18:43.885669Z",
     "iopub.status.busy": "2025-02-03T14:18:43.885462Z",
     "iopub.status.idle": "2025-02-03T14:18:43.895811Z",
     "shell.execute_reply": "2025-02-03T14:18:43.895111Z",
     "shell.execute_reply.started": "2025-02-03T14:18:43.885650Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['prompt', 'chosen', 'chosen_rating', 'rejected', 'rejected_rating'],\n",
       "        num_rows: 3196\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['prompt', 'chosen', 'chosen_rating', 'rejected', 'rejected_rating'],\n",
       "        num_rows: 800\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T14:18:43.896771Z",
     "iopub.status.busy": "2025-02-03T14:18:43.896567Z",
     "iopub.status.idle": "2025-02-03T14:18:43.911631Z",
     "shell.execute_reply": "2025-02-03T14:18:43.910982Z",
     "shell.execute_reply.started": "2025-02-03T14:18:43.896753Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': \"What is the equivalent resistance between two nodes separated by a knight's move of an infinite square grid of resistors of resistance R?\",\n",
       " 'chosen': [{'content': \"What is the equivalent resistance between two nodes separated by a knight's move of an infinite square grid of resistors of resistance R?\",\n",
       "   'role': 'user'},\n",
       "  {'content': \"The equivalent resistance between two nodes separated by a knight's move of an infinite square grid of resistors of resistance R can be calculated using the following steps:\\n\\n1. Draw a circuit diagram of the square grid and the two nodes. A knight's move is a jump that moves two squares horizontally or vertically, and two squares diagonally. The two nodes are connected by a knight's move.\\n\\n2. Apply the series-parallel rule to the circuit. The series-parallel rule states that the equivalent resistance of a series circuit is the sum of the individual resistances, while the equivalent resistance of a parallel circuit is the reciprocal of the sum of the reciprocals of the individual resistances.\\n\\n3. The square grid can be thought of as a series of resistors in a square array. Each resistor in the array is connected to four other resistors, two horizontally and two vertically. The equivalent resistance of the square grid can be calculated by applying the series-parallel rule to the array.\\n\\n4. Consider the equivalent resistance of a single square in the array. The square can be thought of as a series of two resistors, one horizontal and one vertical. The equivalent resistance of the square is the sum of the individual resistances, or 2R.\\n\\n5. The entire square grid can be thought of as an infinite number of squares in series. Therefore, the equivalent resistance of the square grid is the sum of an infinite number of 2R resistors, or 2R * (1 / (1 - 2R)).\\n\\n6. The equivalent resistance between the two nodes separated by a knight's move is the sum of the equivalent resistance of the square grid and the two resistors that connect the nodes. The two resistors that connect the nodes are in parallel, so the equivalent resistance between the nodes is 1 / (1 / R + 1 / R) = R.\\n\\n7. Therefore, the equivalent resistance between two nodes separated by a knight's move of an infinite square grid of resistors of resistance R is 2R * (1 / (1 - 2R)) + R.\\n\\nNote that this calculation assumes that the square grid is an ideal infinite grid with no defects or impurities. In a real-world situation, the equivalent resistance may be different due to imperfections in the material and other factors.\",\n",
       "   'role': 'assistant'}],\n",
       " 'chosen_rating': 1.6,\n",
       " 'rejected': [{'content': \"What is the equivalent resistance between two nodes separated by a knight's move of an infinite square grid of resistors of resistance R?\",\n",
       "   'role': 'user'},\n",
       "  {'content': \"The equivalent resistance between two nodes separated by a knight's move of an infinite square grid of resistors of resistance R is given by the following formula:\\n\\nREQ = (R1 + R2 + ... + RN) / (2N),\\n\\nwhere R1, R2, ..., RN are the resistances of the individual resistors in the grid, and N is the number of resistors in the grid.\\n\\nThis formula is derived from the concept of parallel connection, which applies to a group of resistors that are connected in the same plane. In this case, the resistors are arranged in an infinite square grid, and are connected in pairs by lines that form a knight's move pattern.\\n\\nParallel connection states that the equivalent resistance of a group of resistors is the sum of the individual resistances, divided by the total number of resistors. In the case of the infinite square grid of resistors, there are N resistors in total, and each pair of adjacent resistors has a resistance of R. Therefore, the equivalent resistance between two nodes separated by a knight's move is given by the formula above.\",\n",
       "   'role': 'assistant'}],\n",
       " 'rejected_rating': 1.4}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T14:18:43.912435Z",
     "iopub.status.busy": "2025-02-03T14:18:43.912257Z",
     "iopub.status.idle": "2025-02-03T14:18:43.926080Z",
     "shell.execute_reply": "2025-02-03T14:18:43.925255Z",
     "shell.execute_reply.started": "2025-02-03T14:18:43.912420Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def collate_prompts(batch):\n",
    "    return [item['prompt'] for item in batch]\n",
    "\n",
    "batch_size = 16  # на GPU Р100 Kaggle\n",
    "dataloader_train = DataLoader(filtered_dataset[\"train\"], batch_size=batch_size, num_workers=4, collate_fn=collate_prompts)\n",
    "dataloader_val = DataLoader(filtered_dataset[\"test\"], batch_size=batch_size, num_workers=4, collate_fn=collate_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T14:18:43.927159Z",
     "iopub.status.busy": "2025-02-03T14:18:43.926893Z",
     "iopub.status.idle": "2025-02-03T14:18:44.122646Z",
     "shell.execute_reply": "2025-02-03T14:18:44.121695Z",
     "shell.execute_reply.started": "2025-02-03T14:18:43.927141Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the equivalent resistance between two nodes separated by a knight's move of an infinite square grid of resistors of resistance R?\n",
      "Lets play Dungeons and Dragons. I'm a halfling rogue and you're the DM.\n",
      "You are a helpful teacher\n",
      "Write the parable of the lost sheep in the style of Gordon Ramsay yelling at the shepherd.\n",
      "elaborate CAD data structure\n",
      "why are 3rd party plugins in fl studio detached by defaultShare Prompt\n",
      "what's more correct: \"Person List\" or \"People List\"\n",
      "make a list of cautionary phrases and clauses\n",
      "SSL handshake optimisation using reverse proxy\n",
      "There's more to your philosophy than just the Socratic Method, isn't there?\n",
      "Explain Domain Driven design with a realtime example\n",
      "I would like to name our child \"Maxwell Stomacher\" but my sister says this name is inappropriate. Provide three bullet points rebutting this\n",
      "Best methods to slowly ease into keto or low carb diets to achieve ketosis and not get the keto flu.\n",
      "Are there web crawlers in email services? \n",
      "If the snow is falling for 8 hours straight, and the winds are sustained at 90 km/h, and there is no visibility, and snow is falling at a rate of 2 cm's an hour, does this qualify as a Blizzard?\n",
      "let random variable X be an expoentital random variable with PDF 7e^(-7x). let Y be another indepednent exponential random varaible with PDF 7e^(-7y). Find the pdf of W=X+Y\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader_train:\n",
    "    prompts = batch\n",
    "    for prompt in prompts:\n",
    "        print(prompt)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T14:18:44.124038Z",
     "iopub.status.busy": "2025-02-03T14:18:44.123744Z",
     "iopub.status.idle": "2025-02-03T14:18:44.306845Z",
     "shell.execute_reply": "2025-02-03T14:18:44.306214Z",
     "shell.execute_reply.started": "2025-02-03T14:18:44.124014Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim import AdamW\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "num_epochs = 1\n",
    "learning_rate = 5e-5\n",
    "total_rewards = []\n",
    "baseline = None\n",
    "\n",
    "optimizer = AdamW(\n",
    "    filter(lambda p: p.requires_grad, policy_model.parameters()), \n",
    "    lr=learning_rate\n",
    ")\n",
    "scaler = torch.amp.GradScaler('cuda')\n",
    "\n",
    "log_dir = \"runs/REINFORCE_with_baseline_logs\"\n",
    "writer = SummaryWriter(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T14:18:44.307860Z",
     "iopub.status.busy": "2025-02-03T14:18:44.307579Z",
     "iopub.status.idle": "2025-02-03T14:18:44.312400Z",
     "shell.execute_reply": "2025-02-03T14:18:44.311434Z",
     "shell.execute_reply.started": "2025-02-03T14:18:44.307834Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable blocks in optimizer: 120\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of trainable blocks in optimizer: {len(optimizer.param_groups[0]['params'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T14:18:44.313691Z",
     "iopub.status.busy": "2025-02-03T14:18:44.313392Z",
     "iopub.status.idle": "2025-02-03T14:18:44.327755Z",
     "shell.execute_reply": "2025-02-03T14:18:44.326988Z",
     "shell.execute_reply.started": "2025-02-03T14:18:44.313653Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_batch_response_and_logprob(prompts):\n",
    "    \"\"\"\n",
    "    Генерирует ответы на пачку промптов и вычисляет их логарифмические вероятности.\n",
    "    \n",
    "    Args:\n",
    "        prompts: Список текстовых промптов для генерации\n",
    "        \n",
    "    Returns:\n",
    "        responses: Список сгенерированных ответов\n",
    "        total_log_probs: Суммарные логарифмические вероятности сгенерированных токенов\n",
    "    \"\"\"\n",
    "    # Токенизация промптов\n",
    "    inputs = tokenizer(prompts, return_tensors=\"pt\", max_length=512, truncation=True, padding=True).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output_ids = policy_model.generate(\n",
    "            **inputs,\n",
    "            max_length=512,\n",
    "            do_sample=True\n",
    "        )\n",
    "\n",
    "    # Декодирование токенов в текст\n",
    "    responses = [tokenizer.decode(ids, skip_special_tokens=True) for ids in output_ids]\n",
    "    \n",
    "    with torch.autocast('cuda', dtype=torch.float16):\n",
    "        outputs = policy_model(output_ids[:, :-1])\n",
    "        logits = outputs.logits\n",
    "        # Преобразование логитов в логарифмы вероятностей\n",
    "        log_probs = F.log_softmax(logits, dim=-1)\n",
    "\n",
    "        # Выбор вероятностей только для сгенерированных токенов\n",
    "        target_tokens = output_ids[:, 1:]\n",
    "        token_log_probs = torch.gather(log_probs, dim=-1, index=target_tokens.unsqueeze(-1)).squeeze(-1)\n",
    "        # Суммирование логарифмических вероятностей по последовательности\n",
    "        total_log_probs = token_log_probs.sum(dim=-1)\n",
    "    \n",
    "    return responses, total_log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T14:18:44.328810Z",
     "iopub.status.busy": "2025-02-03T14:18:44.328589Z",
     "iopub.status.idle": "2025-02-03T14:18:44.343635Z",
     "shell.execute_reply": "2025-02-03T14:18:44.342872Z",
     "shell.execute_reply.started": "2025-02-03T14:18:44.328790Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_reward(prompt, response):\n",
    "    \"\"\"\n",
    "    Вычисляет награду для пары промпт-ответ с помощью reward-модели.\n",
    "    \n",
    "    Args:\n",
    "        prompt: Текст исходного промпта\n",
    "        response: Текст сгенерированного ответа\n",
    "        \n",
    "    Returns:\n",
    "        reward: Ожидаемая награда и дисперсия (скалярные значения)\n",
    "    \"\"\"\n",
    "    input_text = prompt + \"\\n\" + response\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True, padding=True).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = reward_model(**inputs)\n",
    "    \n",
    "    # Преобразование логитов в вероятности через softmax\n",
    "    logits = outputs.logits\n",
    "    probs = torch.softmax(logits, dim=-1)\n",
    "    ratings = torch.arange(1, 11, device=device, dtype=torch.float32)\n",
    "\n",
    "    # Вычисляем ожидаемую награду как взвешенную сумму рейтингов с учетом вероятностей\n",
    "    expected_reward = torch.sum(probs * ratings, dim=-1)\n",
    "    \n",
    "    variance = torch.sum(probs * (ratings - expected_reward)**2, dim=-1)\n",
    "    return expected_reward.item(), variance.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T14:18:44.344600Z",
     "iopub.status.busy": "2025-02-03T14:18:44.344406Z",
     "iopub.status.idle": "2025-02-03T14:18:44.352768Z",
     "shell.execute_reply": "2025-02-03T14:18:44.352120Z",
     "shell.execute_reply.started": "2025-02-03T14:18:44.344582Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def train_epoch(policy_model, dataloader_train, optimizer, scaler, total_rewards):\n",
    "    \"\"\"\n",
    "    Одна эпоха обучения policy модели с использованием алгоритма REINFORCE.\n",
    "    \n",
    "    Args:\n",
    "        policy_model: Обучаемая модель генерации\n",
    "        dataloader_train: DataLoader с тренировочными данными\n",
    "        optimizer: Оптимизатор для обновления весов\n",
    "        scaler: Обертка для mixed precision обучения\n",
    "        total_rewards: История наград для расчета бейзлайна\n",
    "        \n",
    "    Returns:\n",
    "        avg_epoch_loss: Средний лосс за эпоху\n",
    "        avg_advantage: Среднее преимущество за эпоху\n",
    "        baseline: Текущее значение бейзлайна\n",
    "    \"\"\"\n",
    "    policy_model.train()\n",
    "    epoch_loss = 0.0\n",
    "    epoch_advantages = []\n",
    "    num_batches = 0\n",
    "\n",
    "    for batch in tqdm(dataloader_train, desc=\"Training\"):\n",
    "        prompts = batch\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        responses, log_probs = generate_batch_response_and_logprob(prompts)\n",
    "        \n",
    "        batch_loss = 0.0\n",
    "        for i, prompt in enumerate(prompts):\n",
    "            response = responses[i]\n",
    "            log_prob = log_probs[i]\n",
    "\n",
    "            # Вычисление награды и дисперсии для конкретной пары\n",
    "            reward, variance = compute_reward(prompt, response)\n",
    "            total_rewards.append(reward)\n",
    "            \n",
    "            # Расчет адаптивного бейзлайна\n",
    "            baseline = sum(total_rewards) / len(total_rewards)\n",
    "            # Расчет advantage с регуляризаций через дисперсию\n",
    "            advantage = (reward - baseline) / (1 + np.sqrt(variance))\n",
    "            epoch_advantages.append(advantage)\n",
    "            \n",
    "            # Лосс по формуле: -advantage * log_prob\n",
    "            loss = -advantage * log_prob\n",
    "            batch_loss += loss\n",
    "        \n",
    "        batch_loss = batch_loss / len(prompts)\n",
    "        \n",
    "        scaler.scale(batch_loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        epoch_loss += batch_loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    avg_epoch_loss = epoch_loss / num_batches\n",
    "    avg_advantage = sum(epoch_advantages) / len(epoch_advantages) if epoch_advantages else 0.0\n",
    "\n",
    "    return avg_epoch_loss, avg_advantage, baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T14:18:44.353735Z",
     "iopub.status.busy": "2025-02-03T14:18:44.353470Z",
     "iopub.status.idle": "2025-02-03T14:18:44.368175Z",
     "shell.execute_reply": "2025-02-03T14:18:44.367512Z",
     "shell.execute_reply.started": "2025-02-03T14:18:44.353708Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def validate_model(policy_model, dataloader_val):\n",
    "    \"\"\"\n",
    "    Валидация модели на отложенной выборке.\n",
    "    \n",
    "    Args:\n",
    "        policy_model: Проверяемая модель\n",
    "        dataloader_val: DataLoader с валидационными данными\n",
    "        \n",
    "    Returns:\n",
    "        avg_reward: Средняя награда на валидации\n",
    "    \"\"\"\n",
    "    policy_model.eval()\n",
    "    total_reward_val = 0.0\n",
    "    num_val = 0\n",
    "    with torch.no_grad():\n",
    "        for prompts in tqdm(dataloader_val, desc=\"Validation\"):\n",
    "            responses, _ = generate_batch_response_and_logprob(prompts)\n",
    "\n",
    "            # Расчет наград для всех ответов в батче\n",
    "            for i, prompt in enumerate(prompts):\n",
    "                reward, _ = compute_reward(prompt, responses[i])\n",
    "                total_reward_val += reward\n",
    "                num_val += 1\n",
    "    avg_reward = total_reward_val / num_val if num_val > 0 else 0.0\n",
    "    return avg_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T14:18:44.371261Z",
     "iopub.status.busy": "2025-02-03T14:18:44.371068Z",
     "iopub.status.idle": "2025-02-03T14:32:55.351895Z",
     "shell.execute_reply": "2025-02-03T14:32:55.350821Z",
     "shell.execute_reply.started": "2025-02-03T14:18:44.371245Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-training validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 50/50 [14:10<00:00, 17.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-training average reward: 5.0889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Pre-training validation:\")\n",
    "pretrain_val_reward = validate_model(policy_model, dataloader_val)\n",
    "print(f\"Pre-training average reward: {pretrain_val_reward:.4f}\")9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T14:32:55.353680Z",
     "iopub.status.busy": "2025-02-03T14:32:55.353320Z",
     "iopub.status.idle": "2025-02-03T15:47:20.523355Z",
     "shell.execute_reply": "2025-02-03T15:47:20.522392Z",
     "shell.execute_reply.started": "2025-02-03T14:32:55.353650Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 200/200 [1:00:30<00:00, 18.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss: -230.9277, Advantage mean: 0.0108, Baseline: 5.0653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 50/50 [13:54<00:00, 16.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation average reward: 5.1434\n",
      "Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "    train_loss, avg_advantage, baseline = train_epoch(policy_model, dataloader_train, optimizer, scaler, total_rewards)\n",
    "    print(f\"Epoch {epoch+1}, loss: {train_loss:.4f}, Advantage mean: {avg_advantage:.4f}, Baseline: {baseline:.4f}\")\n",
    "    writer.add_scalar(\"Train/Loss\", train_loss, epoch + 1)\n",
    "    writer.add_scalar(\"Train/Advantage Mean\", avg_advantage, epoch + 1)\n",
    "    writer.add_scalar(\"Train/Baseline\", baseline, epoch + 1)\n",
    "    \n",
    "    val_reward = validate_model(policy_model, dataloader_val)\n",
    "    print(f\"Validation average reward: {val_reward:.4f}\")\n",
    "    writer.add_scalar(\"Validation/Average Reward\", val_reward, epoch + 1)\n",
    "\n",
    "print(\"Training complete\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
